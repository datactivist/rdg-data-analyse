{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de mots-clés à partir de descriptions\n",
    "Ce notebook permet de charger un ensemble de thésaurus multilingues et d'extraire automatiquement des mots-clés à partir de descriptions en français ou anglais. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation de l'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import langid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du modèle de langage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\") # MODEL 1\n",
    "#model = SentenceTransformer(\"sentence-transformers/LaBSE\") # MODEL 2\n",
    "#model = SentenceTransformer(\"multi-qa-mpnet-base-cos-v1\") #model 3 à essayer\n",
    "model =  SentenceTransformer(\"dangvantuan/sentence-camembert-base\") #model fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement, encodage et stockage des thésaurus dans un dictionnaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 fichiers trouvés : ['agrovoc_terms.csv', 'elsst_terms.csv', 'inrae_terms.csv', 'unesco_terms.csv']\n",
      " Thésaurus chargés : ['agrovoc_terms', 'elsst_terms', 'inrae_terms', 'unesco_terms']\n"
     ]
    }
   ],
   "source": [
    "thesaurus_dir = Path(f\"/Users/labo.adm/Documents/rdg/data/thesaurus/processed\")  \n",
    "thesaurus_files = list(thesaurus_dir.glob(\"*.csv\"))\n",
    "\n",
    "if not thesaurus_files:\n",
    "    print(\" Aucun fichier CSV trouvé dans\", thesaurus_dir.resolve())\n",
    "else:\n",
    "    print(f\" {len(thesaurus_files)} fichiers trouvés :\", [f.name for f in thesaurus_files])\n",
    "\n",
    "def load_thesaurus_and_encode(thesaurus_file):\n",
    "    df = pd.read_csv(thesaurus_file, encoding=\"utf-8\")\n",
    "    if not {\"fr\", \"en\"}.issubset(df.columns):\n",
    "        raise ValueError(f\"Le fichier {thesaurus_file.name} ne contient pas les colonnes 'fr' et 'en'\")\n",
    "    \n",
    "    df = df[[\"fr\", \"en\"]].dropna()\n",
    "    data = {}\n",
    "    for lang in [\"fr\", \"en\"]:\n",
    "        terms = df[lang].tolist()\n",
    "        embeddings = model.encode(terms, convert_to_tensor=True)\n",
    "        data[lang] = {\n",
    "            \"candidates\": terms,\n",
    "            \"embeddings\": embeddings\n",
    "        }\n",
    "    return data\n",
    "\n",
    "thesaurus_data = {}\n",
    "for file in thesaurus_files:\n",
    "    try:\n",
    "        name = file.stem\n",
    "        thesaurus_data[name] = load_thesaurus_and_encode(file)\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur avec {file.name} : {e}\")\n",
    "\n",
    "print(f\" Thésaurus chargés : {list(thesaurus_data.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauvegarde le dictionnaire créé avec les embeddings des thésaurus pour pouvoir le recharger et ne pas refaire l'étape précédente qui prend beaucoup de temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thésaurus sauvegardé dans C:\\Users\\labo.adm\\Documents\\rdg\\notebooks\\thesaurus_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# save thesaurus_data to a file\n",
    "import pickle\n",
    "thesaurus_data_file = Path(\"thesaurus_data.pkl\")\n",
    "with open(thesaurus_data_file, \"wb\") as f:\n",
    "    pickle.dump(thesaurus_data, f)\n",
    "print(f\" Thésaurus sauvegardé dans {thesaurus_data_file.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge le dictionnaire précédemment enregistré. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load thesaurus_data from a file\n",
    "with open(thesaurus_data_file, \"rb\") as f:\n",
    "    thesaurus_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction qui prédit les mots-clés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keywords(doc, lang, thesaurus_data, n=5, threshold=0.25):\n",
    "    if lang not in [\"fr\", \"en\"]:\n",
    "        lang = \"fr\"  \n",
    "    doc_embedding = model.encode(doc, convert_to_tensor=True)\n",
    "\n",
    "    results_by_thesaurus = {}\n",
    "    all_keywords = []\n",
    "\n",
    "    for thesaurus_name, data in thesaurus_data.items():\n",
    "        if lang not in data:\n",
    "            continue\n",
    "\n",
    "        candidates = data[lang][\"candidates\"]\n",
    "        embeddings = data[lang][\"embeddings\"]\n",
    "        scores = util.cos_sim(doc_embedding, embeddings)[0]\n",
    "\n",
    "        thesaurus_results = []\n",
    "        for kw, score in zip(candidates, scores):\n",
    "            score_val = float(score)\n",
    "            if score_val >= threshold:\n",
    "                thesaurus_results.append((kw, score_val))\n",
    "                all_keywords.append((kw, score_val, thesaurus_name))\n",
    "\n",
    "        thesaurus_results = sorted(thesaurus_results, key=lambda x: x[1], reverse=True)[:n]\n",
    "        results_by_thesaurus[thesaurus_name] = thesaurus_results\n",
    "\n",
    "    top_all = sorted(all_keywords, key=lambda x: x[1], reverse=True)[:n]\n",
    "    return results_by_thesaurus, top_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description et détection de la langue.\n",
    "Dans ce bloc on insère la description à partir de laquelle on veut extraire les mots-clés. \n",
    "Attention de bien l'insérer entre [\"\"\" \"\"\"], cela évite des erreurs avec les guillemets présents dans le texte. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [\n",
    "    \"\"\" \n",
    "Les données présentées ont été produites dans le contexte de l'étude des jeux sérieux, et plus particulièrement de la définition de la relation entre éléments pédagogiques et éléments ludiques établie par les modèles de jeux sérieux de la littérature. Les 4 tableaux composant ce jeu présentent des valeurs exprimant la représentativité d'un modèle (en colonnes) par rapport aux catégories d'un thésaurus de référence (en lignes). Pour chaque modèle, 2 valeurs sont calculées par thésaurus : une compensatoire (additive) et une semi-compensatoire (multiplicative). Les 2 thésauri utilisés ici sont éduthès (https://eduthes.cdc.qc.ca/vocab/index.php) et le Thésaurus Européen d'Éducation (https://vocabularyserver.com/tee/fr/). Pour chaque tableau, plusieurs données sont précisées par rapport aux valeurs (intervalle, quartiles, médiane, …). French (2025-05-07) \"\"\"\n",
    "]\n",
    "languages = [langid.classify(text)[0] for text in descriptions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On applique la fonction à la description. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Description :  \n",
      "Les données présentées ont été produites dans le contexte de l'étude des jeux sérieux, et plus particulièrement de la définition de la relation entre éléments pédagogiques et éléments ludiques établie par les modèles de jeux sérieux de la littérature. Les 4 tableaux composant ce jeu présentent des valeurs exprimant la représentativité d'un modèle (en colonnes) par rapport aux catégories d'un thésaurus de référence (en lignes). Pour chaque modèle, 2 valeurs sont calculées par thésaurus : une compensatoire (additive) et une semi-compensatoire (multiplicative). Les 2 thésauri utilisés ici sont éduthès (https://eduthes.cdc.qc.ca/vocab/index.php) et le Thésaurus Européen d'Éducation (https://vocabularyserver.com/tee/fr/). Pour chaque tableau, plusieurs données sont précisées par rapport aux valeurs (intervalle, quartiles, médiane, …). French (2025-05-07) \n",
      " Langue détectée : fr\n",
      "\n",
      " Voici les résultats par thésaurus :\n",
      "  - agrovoc_terms: Théorie axiomatique des ensembles (0.329) ; Équations intégro-différentielles (0.295) ; Fonctions de plusieurs variables complexes (0.262)\n",
      "  - elsst_terms: \n",
      "  - inrae_terms: méthode de calcul par approximation de Bayes (0.304) ; 11.01 MÉTHODES DE MESURE, D'OBSERVATION ET D'ANALYSE (0.304) ; équation intégro-différentielle (0.274) ; réaction de polymérisation en chaîne par transcription inverse (0.259) ; analyse factorielle discriminante (0.251)\n",
      "  - unesco_terms: \n",
      "\n",
      " Voici le Top 5 des mots-clés :\n",
      "  Théorie axiomatique des ensembles (0.329) [agrovoc_terms]\n",
      "  méthode de calcul par approximation de Bayes (0.304) [inrae_terms]\n",
      "  11.01 MÉTHODES DE MESURE, D'OBSERVATION ET D'ANALYSE (0.304) [inrae_terms]\n",
      "  Équations intégro-différentielles (0.295) [agrovoc_terms]\n",
      "  équation intégro-différentielle (0.274) [inrae_terms]\n"
     ]
    }
   ],
   "source": [
    "for description, lang in zip(descriptions, languages):\n",
    "    print(f\"\\n Description : {description}\")\n",
    "    print(f\" Langue détectée : {lang}\")\n",
    "\n",
    "    results_struct, top_all = predict_keywords(description, lang, thesaurus_data)\n",
    "\n",
    "    print(\"\\n Voici les résultats par thésaurus :\")\n",
    "    for thesaurus_name, keywords in results_struct.items():\n",
    "        keywords_str = \" ; \".join(f\"{kw} ({score:.3f})\" for kw, score in keywords)\n",
    "        print(f\"  - {thesaurus_name}: {keywords_str}\")\n",
    "\n",
    "    print(\"\\n Voici le Top 5 des mots-clés :\")\n",
    "    for kw, score, thesaurus in top_all:\n",
    "        print(f\"  {kw} ({score:.3f}) [{thesaurus}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour avoir la traduction des mots-clés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translations_by_thesaurus_index(thesaurus_data, keywords_by_thesaurus, lang):\n",
    "    def normalize(s):\n",
    "        return s.strip().lower()\n",
    "\n",
    "    other_lang = \"fr\" if lang == \"en\" else \"en\"\n",
    "    translations_by_thesaurus = {}\n",
    "\n",
    "    for thesaurus_name, detected_keywords in keywords_by_thesaurus.items():\n",
    "        if thesaurus_name not in thesaurus_data:\n",
    "            continue\n",
    "\n",
    "        data = thesaurus_data[thesaurus_name]\n",
    "        if lang not in data or other_lang not in data:\n",
    "            continue\n",
    "\n",
    "        source_list = data[lang][\"candidates\"]\n",
    "        target_list = data[other_lang][\"candidates\"]\n",
    "\n",
    "        # Création d'une map normalisée : terme normalisé → index\n",
    "        normalized_index_map = {\n",
    "            normalize(term): i for i, term in enumerate(source_list)\n",
    "        }\n",
    "\n",
    "        translations = []\n",
    "        for kw in detected_keywords:\n",
    "            norm_kw = normalize(kw)\n",
    "            if norm_kw in normalized_index_map:\n",
    "                idx = normalized_index_map[norm_kw]\n",
    "                if idx < len(target_list):\n",
    "                    translations.append(target_list[idx])\n",
    "                else:\n",
    "                    translations.append(\"(non traduit)\")\n",
    "            else:\n",
    "                translations.append(\"(non traduit)\")\n",
    "\n",
    "        translations_by_thesaurus[thesaurus_name] = translations\n",
    "\n",
    "    return translations_by_thesaurus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On applique la fonction précédente et on affiche les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Description :  \n",
      "Les données présentées ont été produites dans le contexte de l'étude des jeux sérieux, et plus particulièrement de la définition de la relation entre éléments pédagogiques et éléments ludiques établie par les modèles de jeux sérieux de la littérature. Les 4 tableaux composant ce jeu présentent des valeurs exprimant la représentativité d'un modèle (en colonnes) par rapport aux catégories d'un thésaurus de référence (en lignes). Pour chaque modèle, 2 valeurs sont calculées par thésaurus : une compensatoire (additive) et une semi-compensatoire (multiplicative). Les 2 thésauri utilisés ici sont éduthès (https://eduthes.cdc.qc.ca/vocab/index.php) et le Thésaurus Européen d'Éducation (https://vocabularyserver.com/tee/fr/). Pour chaque tableau, plusieurs données sont précisées par rapport aux valeurs (intervalle, quartiles, médiane, …). French (2025-05-07) \n",
      "Langue détectée : fr\n",
      "\n",
      "Voici les mots-clés et leur traduction (en) :\n",
      "  - agrovoc_terms:\n",
      "      Théorie axiomatique des ensembles → Axiomatic set theory\n",
      "      Équations intégro-différentielles → Integro-differential equations\n",
      "      Fonctions de plusieurs variables complexes → Functions of several complex variables\n",
      "  - elsst_terms:\n",
      "  - inrae_terms:\n",
      "      méthode de calcul par approximation de Bayes → Approximate Bayesian Computation\n",
      "      11.01 MÉTHODES DE MESURE, D'OBSERVATION ET D'ANALYSE → 11.01 RESEARCH METHODS\n",
      "      équation intégro-différentielle → integro-differential equation\n",
      "      réaction de polymérisation en chaîne par transcription inverse → reverse transcriptase polymerase chain reaction\n",
      "      analyse factorielle discriminante → linear discriminant analysis\n",
      "  - unesco_terms:\n"
     ]
    }
   ],
   "source": [
    "# Affichage des mots-clés dans l'autre langue\n",
    "for description, lang in zip(descriptions, languages):\n",
    "    print(f\"\\nDescription : {description}\")\n",
    "    print(f\"Langue détectée : {lang}\")\n",
    "\n",
    "    results_struct, top_all = predict_keywords(description, lang, thesaurus_data)\n",
    "\n",
    "\n",
    "keywords_by_thesaurus = {\n",
    "    th_name: [kw for kw, *_ in kws]\n",
    "    for th_name, kws in results_struct.items()\n",
    "}\n",
    "\n",
    "translations_by_thesaurus = get_translations_by_thesaurus_index(\n",
    "    thesaurus_data,\n",
    "    keywords_by_thesaurus,\n",
    "    lang\n",
    ")\n",
    "\n",
    "print(f\"\\nVoici les mots-clés et leur traduction ({'en' if lang == 'fr' else 'fr'}) :\")\n",
    "for thesaurus_name, translations in translations_by_thesaurus.items():\n",
    "    print(f\"  - {thesaurus_name}:\")\n",
    "    for original_kw, translated_kw in zip(keywords_by_thesaurus[thesaurus_name], translations):\n",
    "        print(f\"      {original_kw} → {translated_kw}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
